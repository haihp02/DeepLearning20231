{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7200583,"sourceType":"datasetVersion","datasetId":4164996}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T12:30:44.375586Z","iopub.execute_input":"2023-12-14T12:30:44.375874Z","iopub.status.idle":"2023-12-14T12:30:59.671598Z","shell.execute_reply.started":"2023-12-14T12:30:44.375848Z","shell.execute_reply":"2023-12-14T12:30:59.670519Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.36.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=c1f6d46f4ba40092f9f56fd162ffc4c12281c6c41e178263d31c7474ab9ca82a\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers.evaluation import SentenceEvaluator\nimport torch\nfrom torch import Tensor\nimport logging\nfrom tqdm import tqdm, trange\nfrom sentence_transformers.util import cos_sim, dot_score\nimport os\nimport numpy as np\nfrom typing import List, Tuple, Dict, Set, Callable\nimport heapq\nimport pickle\n\n\nlogger = logging.getLogger(__name__)\n\nclass InformationRetrievalEvaluator(SentenceEvaluator):\n    \"\"\"\n    This class evaluates an Information Retrieval (IR) setting.\n\n    Given a set of queries and a large corpus set. It will retrieve for each query the top-k most similar document. It measures\n    Mean Reciprocal Rank (MRR), Recall@k, and Normalized Discounted Cumulative Gain (NDCG)\n    \"\"\"\n\n    def __init__(self,\n                 queries: Dict[str, str],  #qid => query\n                 corpus: Dict[str, str],  #cid => doc\n                 relevant_docs: Dict[str, Set[str]],  #qid => Set[cid]\n                 corpus_chunk_size: int = 50000,\n                 mrr_at_k: List[int] = [10],\n                 ndcg_at_k: List[int] = [10],\n                 accuracy_at_k: List[int] = [1, 3, 5, 10],\n                 precision_recall_at_k: List[int] = [1, 3, 5, 10],\n                 map_at_k: List[int] = [100],\n                 show_progress_bar: bool = False,\n                 batch_size: int = 32,\n                 name: str = '',\n                 write_csv: bool = True,\n                 score_functions: List[Callable[[Tensor, Tensor], Tensor] ] = {'cos_sim': cos_sim, 'dot_score': dot_score},       #Score function, higher=more similar\n                 main_score_function: str = None\n                 ):\n\n        self.queries_ids = []\n        for qid in queries:\n            if qid in relevant_docs and len(relevant_docs[qid]) > 0:\n                self.queries_ids.append(qid)\n\n        self.queries = [queries[qid] for qid in self.queries_ids]\n\n        self.corpus_ids = list(corpus.keys())\n        self.corpus = [corpus[cid] for cid in self.corpus_ids]\n\n        self.relevant_docs = relevant_docs\n        self.corpus_chunk_size = corpus_chunk_size\n        self.mrr_at_k = mrr_at_k\n        self.ndcg_at_k = ndcg_at_k\n        self.accuracy_at_k = accuracy_at_k\n        self.precision_recall_at_k = precision_recall_at_k\n        self.map_at_k = map_at_k\n\n        self.show_progress_bar = show_progress_bar\n        self.batch_size = batch_size\n        self.name = name\n        self.write_csv = write_csv\n        self.score_functions = score_functions\n        self.score_function_names = sorted(list(self.score_functions.keys()))\n        self.main_score_function = main_score_function\n\n        if name:\n            name = \"_\" + name\n\n        self.csv_file: str = \"Information-Retrieval_evaluation\" + name + \"_results.csv\"\n        self.csv_headers = [\"epoch\", \"steps\"]\n\n        for score_name in self.score_function_names:\n            for k in accuracy_at_k:\n                self.csv_headers.append(\"{}-Accuracy@{}\".format(score_name, k))\n\n            for k in precision_recall_at_k:\n                self.csv_headers.append(\"{}-Precision@{}\".format(score_name, k))\n                self.csv_headers.append(\"{}-Recall@{}\".format(score_name, k))\n\n            for k in mrr_at_k:\n                self.csv_headers.append(\"{}-MRR@{}\".format(score_name, k))\n\n            for k in ndcg_at_k:\n                self.csv_headers.append(\"{}-NDCG@{}\".format(score_name, k))\n\n            for k in map_at_k:\n                self.csv_headers.append(\"{}-MAP@{}\".format(score_name, k))\n\n    def __call__(self, model,  epoch: int = -1, steps: int = -1, *args, **kwargs) -> float:\n        if epoch != -1:\n            out_txt = \" after epoch {}:\".format(epoch) if steps == -1 else \" in epoch {} after {} steps:\".format(epoch, steps)\n        else:\n            out_txt = \":\"\n\n        logger.info(\"Information Retrieval Evaluation on \" + self.name + \" dataset\" + out_txt)\n\n        scores = self.compute_metrices(model, *args, **kwargs)\n        # Write results to disc\n        if  self.write_csv:\n            csv_path = os.path.join('./', self.csv_file)\n            if not os.path.isfile(csv_path):\n                fOut = open(csv_path, mode=\"w\", encoding=\"utf-8\")\n                fOut.write(\",\".join(self.csv_headers))\n                fOut.write(\"\\n\")\n\n            else:\n                fOut = open(csv_path, mode=\"a\", encoding=\"utf-8\")\n\n            output_data = [epoch, steps]\n            for name in self.score_function_names:\n                for k in self.accuracy_at_k:\n                    output_data.append(scores[name]['accuracy@k'][k])\n\n                for k in self.precision_recall_at_k:\n                    output_data.append(scores[name]['precision@k'][k])\n                    output_data.append(scores[name]['recall@k'][k])\n\n                for k in self.mrr_at_k:\n                    output_data.append(scores[name]['mrr@k'][k])\n\n                for k in self.ndcg_at_k:\n                    output_data.append(scores[name]['ndcg@k'][k])\n\n                for k in self.map_at_k:\n                    output_data.append(scores[name]['map@k'][k])\n\n            fOut.write(\",\".join(map(str, output_data)))\n            fOut.write(\"\\n\")\n            fOut.close()\n\n        if self.main_score_function is None:\n            return max([scores[name]['map@k'][max(self.map_at_k)] for name in self.score_function_names])\n        else:\n            return scores[self.main_score_function]['map@k'][max(self.map_at_k)]\n\n    def compute_metrices(self, model, corpus_model = None, corpus_embeddings: Tensor = None) -> Dict[str, float]:\n        if corpus_model is None:\n            corpus_model = model\n\n        max_k = max(max(self.mrr_at_k), max(self.ndcg_at_k), max(self.accuracy_at_k), max(self.precision_recall_at_k), max(self.map_at_k))\n\n        # Compute embedding for the queries\n        query_embeddings = model.encode(self.queries, show_progress_bar=self.show_progress_bar, batch_size=self.batch_size, convert_to_tensor=True)\n\n        queries_result_list = {}\n        for name in self.score_functions:\n            queries_result_list[name] = [[] for _ in range(len(query_embeddings))]\n\n        #Iterate over chunks of the corpus\n        for corpus_start_idx in trange(0, len(self.corpus), self.corpus_chunk_size, desc='Corpus Chunks', disable=not self.show_progress_bar):\n            corpus_end_idx = min(corpus_start_idx + self.corpus_chunk_size, len(self.corpus))\n\n            #Encode chunk of corpus\n            if corpus_embeddings is None:\n                sub_corpus_embeddings = corpus_model.encode(self.corpus[corpus_start_idx:corpus_end_idx], show_progress_bar=False, batch_size=self.batch_size, convert_to_tensor=True)\n            else:\n                sub_corpus_embeddings = corpus_embeddings[corpus_start_idx:corpus_end_idx]\n\n            #Compute cosine similarites\n            for name, score_function in self.score_functions.items():\n                pair_scores = score_function(query_embeddings, sub_corpus_embeddings)\n\n                #Get top-k values\n                pair_scores_top_k_values, pair_scores_top_k_idx = torch.topk(pair_scores, min(max_k, len(pair_scores[0])), dim=1, largest=True, sorted=False)\n                pair_scores_top_k_values = pair_scores_top_k_values.cpu().tolist()\n                pair_scores_top_k_idx = pair_scores_top_k_idx.cpu().tolist()\n\n                for query_itr in range(len(query_embeddings)):\n                    for sub_corpus_id, score in zip(pair_scores_top_k_idx[query_itr], pair_scores_top_k_values[query_itr]):\n                        corpus_id = self.corpus_ids[corpus_start_idx+sub_corpus_id]\n                        if len(queries_result_list[name][query_itr]) < max_k:\n                            heapq.heappush(queries_result_list[name][query_itr], (score, corpus_id))  # heaqp tracks the quantity of the first element in the tuple\n                        else:\n                            heapq.heappushpop(queries_result_list[name][query_itr], (score, corpus_id))\n\n        for name in queries_result_list:\n            for query_itr in range(len(queries_result_list[name])):\n                for doc_itr in range(len(queries_result_list[name][query_itr])):\n                    score, corpus_id = queries_result_list[name][query_itr][doc_itr]\n                    queries_result_list[name][query_itr][doc_itr] = {'corpus_id': corpus_id, 'score': score}\n\n        logger.info(\"Queries: {}\".format(len(self.queries)))\n        logger.info(\"Corpus: {}\\n\".format(len(self.corpus)))\n        logger.info(\"Saving queries_result_list.pkl\")\n        with open('queries_result_list.pkl', 'wb') as f:\n            pickle.dump(queries_result_list, f)\n        #Compute scores\n        logger.info(\"Computing scores...\")\n        scores = {name: self.compute_metrics(queries_result_list[name]) for name in self.score_functions}\n        \n        #Output\n        for name in self.score_function_names:\n            logger.info(\"Score-Function: {}\".format(name))\n            self.output_scores(scores[name])\n\n        return scores\n\n\n    def compute_metrics(self, queries_result_list: List[object]):\n        # Init score computation values\n        num_hits_at_k = {k: 0 for k in self.accuracy_at_k}\n        precisions_at_k = {k: [] for k in self.precision_recall_at_k}\n        recall_at_k = {k: [] for k in self.precision_recall_at_k}\n        MRR = {k: 0 for k in self.mrr_at_k}\n        ndcg = {k: [] for k in self.ndcg_at_k}\n        AveP_at_k = {k: [] for k in self.map_at_k}\n\n        # Compute scores on results\n        for query_itr in range(len(queries_result_list)):\n            query_id = self.queries_ids[query_itr]\n\n            # Sort scores\n            top_hits = sorted(queries_result_list[query_itr], key=lambda x: x['score'], reverse=True)\n            query_relevant_docs = self.relevant_docs[query_id]\n\n            # Accuracy@k - We count the result correct, if at least one relevant doc is across the top-k documents\n            for k_val in self.accuracy_at_k:\n                for hit in top_hits[0:k_val]:\n                    if hit['corpus_id'] in query_relevant_docs:\n                        num_hits_at_k[k_val] += 1\n                        break\n\n            # Precision and Recall@k\n            for k_val in self.precision_recall_at_k:\n                num_correct = 0\n                for hit in top_hits[0:k_val]:\n                    if hit['corpus_id'] in query_relevant_docs:\n                        num_correct += 1\n\n                precisions_at_k[k_val].append(num_correct / k_val)\n                recall_at_k[k_val].append(num_correct / len(query_relevant_docs))\n\n            # MRR@k\n            for k_val in self.mrr_at_k:\n                for rank, hit in enumerate(top_hits[0:k_val]):\n                    if hit['corpus_id'] in query_relevant_docs:\n                        MRR[k_val] += 1.0 / (rank + 1)\n                        break\n\n            # NDCG@k\n            for k_val in self.ndcg_at_k:\n                predicted_relevance = [1 if top_hit['corpus_id'] in query_relevant_docs else 0 for top_hit in top_hits[0:k_val]]\n                true_relevances = [1] * len(query_relevant_docs)\n\n                ndcg_value = self.compute_dcg_at_k(predicted_relevance, k_val) / self.compute_dcg_at_k(true_relevances, k_val)\n                ndcg[k_val].append(ndcg_value)\n\n            # MAP@k\n            for k_val in self.map_at_k:\n                num_correct = 0\n                sum_precisions = 0\n\n                for rank, hit in enumerate(top_hits[0:k_val]):\n                    if hit['corpus_id'] in query_relevant_docs:\n                        num_correct += 1\n                        sum_precisions += num_correct / (rank + 1)\n\n                avg_precision = sum_precisions / min(k_val, len(query_relevant_docs))\n                AveP_at_k[k_val].append(avg_precision)\n\n        # Compute averages\n        for k in num_hits_at_k:\n            num_hits_at_k[k] /= len(self.queries)\n\n        for k in precisions_at_k:\n            precisions_at_k[k] = np.mean(precisions_at_k[k])\n\n        for k in recall_at_k:\n            recall_at_k[k] = np.mean(recall_at_k[k])\n\n        for k in ndcg:\n            ndcg[k] = np.mean(ndcg[k])\n\n        for k in MRR:\n            MRR[k] /= len(self.queries)\n\n        for k in AveP_at_k:\n            AveP_at_k[k] = np.mean(AveP_at_k[k])\n\n\n        return {'accuracy@k': num_hits_at_k, 'precision@k': precisions_at_k, 'recall@k': recall_at_k, 'ndcg@k': ndcg, 'mrr@k': MRR, 'map@k': AveP_at_k}\n\n\n    def output_scores(self, scores):\n        for k in scores['accuracy@k']:\n            logger.info(\"Accuracy@{}: {:.2f}%\".format(k, scores['accuracy@k'][k]*100))\n\n        for k in scores['precision@k']:\n            logger.info(\"Precision@{}: {:.2f}%\".format(k, scores['precision@k'][k]*100))\n\n        for k in scores['recall@k']:\n            logger.info(\"Recall@{}: {:.2f}%\".format(k, scores['recall@k'][k]*100))\n\n        for k in scores['mrr@k']:\n            logger.info(\"MRR@{}: {:.4f}\".format(k, scores['mrr@k'][k]))\n\n        for k in scores['ndcg@k']:\n            logger.info(\"NDCG@{}: {:.4f}\".format(k, scores['ndcg@k'][k]))\n\n        for k in scores['map@k']:\n            logger.info(\"MAP@{}: {:.4f}\".format(k, scores['map@k'][k]))\n\n\n    @staticmethod\n    def compute_dcg_at_k(relevances, k):\n        dcg = 0\n        for i in range(min(len(relevances), k)):\n            dcg += relevances[i] / np.log2(i + 2)  #+2 as we start our idx at 0\n        return dcg\n    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:29:11.808549Z","iopub.execute_input":"2023-12-14T13:29:11.809221Z","iopub.status.idle":"2023-12-14T13:29:11.864011Z","shell.execute_reply.started":"2023-12-14T13:29:11.809183Z","shell.execute_reply":"2023-12-14T13:29:11.863032Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\nfrom sentence_transformers import models,SentenceTransformer\nimport logging\nimport sys\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:31:42.717011Z","iopub.execute_input":"2023-12-14T12:31:42.717711Z","iopub.status.idle":"2023-12-14T12:31:42.721894Z","shell.execute_reply.started":"2023-12-14T12:31:42.717676Z","shell.execute_reply":"2023-12-14T12:31:42.720920Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_name = 'all-MiniLM-L6-v2'","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:31:58.912607Z","iopub.execute_input":"2023-12-14T12:31:58.913500Z","iopub.status.idle":"2023-12-14T12:31:58.917395Z","shell.execute_reply.started":"2023-12-14T12:31:58.913463Z","shell.execute_reply":"2023-12-14T12:31:58.916534Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:32:00.324262Z","iopub.execute_input":"2023-12-14T12:32:00.324639Z","iopub.status.idle":"2023-12-14T12:32:11.059816Z","shell.execute_reply.started":"2023-12-14T12:32:00.324608Z","shell.execute_reply":"2023-12-14T12:32:11.059008Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfb03e34960a41d99e2b79f9830e599e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5408a458d4b8404597d1554350ad720c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c10b6f99de6e47fc98042223d95eb153"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5bc1cf6398c431aba1ab266b6fa612d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1f3e902c924536b8310399b2aa63b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"181fb4cb69b3413a8a45579dbb4beee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f0cb0e510b14e2390366c05f98d3abc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ecd968d18394ebaab00dd2da62d2fd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b61bb6b18444334aaddbc19536e77fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0088725746476381d1795447269c27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51ed35464c51472ea9af5ecff8431424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb2c098a665a4cb595a81fec0bbaa871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf897a0420e4a84aa0a361d513b3c37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db164eb076254b0d857c6b8aac2ef3c5"}},"metadata":{}}]},{"cell_type":"code","source":"import pickle\ndev_qrels = pickle.load(open('/kaggle/input/ms-marco-for-eval/dataset_in_use/dev_qrels_first_10k_with_bm25_top1000.pkl','rb'))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:33:03.589231Z","iopub.execute_input":"2023-12-14T12:33:03.589596Z","iopub.status.idle":"2023-12-14T12:33:05.817678Z","shell.execute_reply.started":"2023-12-14T12:33:03.589567Z","shell.execute_reply":"2023-12-14T12:33:05.816883Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\ncorpus = {}             #Our corpus pid => passage\nqueries = {}        #Our dev queries. qid => query\ndev_rel_docs = {}       #Mapping qid => set with relevant pids\nneeded_pids = set()     #Passage IDs we need\nneeded_qids = set()     #Query IDs we need\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:33:15.480885Z","iopub.execute_input":"2023-12-14T12:33:15.481249Z","iopub.status.idle":"2023-12-14T12:33:15.486707Z","shell.execute_reply.started":"2023-12-14T12:33:15.481219Z","shell.execute_reply":"2023-12-14T12:33:15.485768Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dev_queries_file = '/kaggle/input/ms-marco-for-eval/dataset_in_use/queries.dev.tsv'\ntrain_queries_file = '/kaggle/input/ms-marco-for-eval/dataset_in_use/queries.train.tsv'\neval_queries_file = '/kaggle/input/ms-marco-for-eval/dataset_in_use/queries.eval.tsv'\nwith open(dev_queries_file, encoding='utf8') as fIn:\n    for line in fIn:\n        qid, query = line.strip().split(\"\\t\")\n        queries[int(qid)] = query.strip()\n\nwith open(train_queries_file, encoding='utf8') as fIn:\n    for line in fIn:\n        qid, query = line.strip().split(\"\\t\")\n        queries[int(qid)] = query.strip()\nwith open(eval_queries_file, encoding='utf8') as fIn:\n    for line in fIn:\n        qid, query = line.strip().split(\"\\t\")\n        queries[int(qid)] = query.strip()\n\n        \n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:33:55.251203Z","iopub.execute_input":"2023-12-14T12:33:55.251983Z","iopub.status.idle":"2023-12-14T12:33:56.552953Z","shell.execute_reply.started":"2023-12-14T12:33:55.251950Z","shell.execute_reply":"2023-12-14T12:33:56.552124Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Read passages\nwith open('/kaggle/input/ms-marco-for-eval/dataset_in_use/collection_in_use.tsv', encoding='utf8') as fIn:\n    for line in fIn:\n        pid, passage = line.strip().split(\"\\t\")\n        passage = passage\n        corpus[int(pid)] = passage.strip()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:34:18.798068Z","iopub.execute_input":"2023-12-14T12:34:18.798418Z","iopub.status.idle":"2023-12-14T12:34:22.936661Z","shell.execute_reply.started":"2023-12-14T12:34:18.798392Z","shell.execute_reply":"2023-12-14T12:34:22.935663Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dev_queries = {}\nfor x in dev_qrels:\n    dev_queries[x['qid']] = queries[x['qid']]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:34:25.649679Z","iopub.execute_input":"2023-12-14T12:34:25.650071Z","iopub.status.idle":"2023-12-14T12:34:25.664398Z","shell.execute_reply.started":"2023-12-14T12:34:25.650043Z","shell.execute_reply":"2023-12-14T12:34:25.663249Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for x in dev_qrels:\n    qid,pid = x['qid'],x['pid']\n    if qid not in dev_queries:\n            continue\n    if qid not in dev_rel_docs:\n        dev_rel_docs[qid] = set()\n    dev_rel_docs[qid].add(pid)\n    needed_pids.add(pid)\n    needed_qids.add(qid)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T12:34:32.447542Z","iopub.execute_input":"2023-12-14T12:34:32.447919Z","iopub.status.idle":"2023-12-14T12:34:32.474440Z","shell.execute_reply.started":"2023-12-14T12:34:32.447889Z","shell.execute_reply":"2023-12-14T12:34:32.473491Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"ir_evaluator = InformationRetrievalEvaluator(dev_queries, corpus, dev_rel_docs,\n                                                        show_progress_bar=True,\n                                                        corpus_chunk_size=100000,\n                                                        precision_recall_at_k=[10, 100],\n                                                        name=\"msmarco dev\",\n                                                        write_csv = True)\n\nir_evaluator(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:15:58.546711Z","iopub.execute_input":"2023-12-14T13:15:58.547566Z","iopub.status.idle":"2023-12-14T13:26:06.339910Z","shell.execute_reply.started":"2023-12-14T13:15:58.547532Z","shell.execute_reply":"2023-12-14T13:26:06.338878Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8fb15e53f5e49578e92719e208b0734"}},"metadata":{}},{"name":"stderr","text":"Corpus Chunks: 100%|██████████| 10/10 [10:00<00:00, 60.09s/it]\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"0.6195057515472899"},"metadata":{}}]},{"cell_type":"code","source":"res = pickle.load(open('/kaggle/working/scores.pkl','rb'))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:26:56.413817Z","iopub.execute_input":"2023-12-14T13:26:56.414199Z","iopub.status.idle":"2023-12-14T13:26:56.419767Z","shell.execute_reply.started":"2023-12-14T13:26:56.414172Z","shell.execute_reply":"2023-12-14T13:26:56.418582Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"res","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:26:57.384708Z","iopub.execute_input":"2023-12-14T13:26:57.385674Z","iopub.status.idle":"2023-12-14T13:26:57.393742Z","shell.execute_reply.started":"2023-12-14T13:26:57.385631Z","shell.execute_reply":"2023-12-14T13:26:57.392609Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'cos_sim': {'accuracy@k': {1: 0.5044600692622521,\n   3: 0.7041662294049743,\n   5: 0.7717493965788645,\n   10: 0.8480428166649177},\n  'precision@k': {10: 0.08751180606569421, 100: 0.010086053101059922},\n  'recall@k': {10: 0.8408927134711582, 100: 0.9629919194039249},\n  'ndcg@k': {10: 0.6701923440702828},\n  'mrr@k': {10: 0.6188801686414217},\n  'map@k': {100: 0.6195057515472899}},\n 'dot_score': {'accuracy@k': {1: 0.5044600692622521,\n   3: 0.7041662294049743,\n   5: 0.7717493965788645,\n   10: 0.8480428166649177},\n  'precision@k': {10: 0.08751180606569421, 100: 0.010086053101059922},\n  'recall@k': {10: 0.8408927134711582, 100: 0.9629919194039249},\n  'ndcg@k': {10: 0.6701923440702828},\n  'mrr@k': {10: 0.6188801686414217},\n  'map@k': {100: 0.6195057515472899}}}"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf_result = pd.read_csv('/kaggle/working/Information-Retrieval_evaluation_msmarco dev_results.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:27:42.235382Z","iopub.execute_input":"2023-12-14T13:27:42.236234Z","iopub.status.idle":"2023-12-14T13:27:42.559458Z","shell.execute_reply.started":"2023-12-14T13:27:42.236198Z","shell.execute_reply":"2023-12-14T13:27:42.558692Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_result","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:33:32.631477Z","iopub.execute_input":"2023-12-14T13:33:32.631872Z","iopub.status.idle":"2023-12-14T13:33:32.651759Z","shell.execute_reply.started":"2023-12-14T13:33:32.631841Z","shell.execute_reply":"2023-12-14T13:33:32.650852Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"   epoch  steps  cos_sim-Accuracy@1  cos_sim-Accuracy@3  cos_sim-Accuracy@5  \\\n0     -1     -1             0.50446            0.704166            0.771749   \n\n   cos_sim-Accuracy@10  cos_sim-Precision@10  cos_sim-Recall@10  \\\n0             0.848043              0.087512           0.840893   \n\n   cos_sim-Precision@100  cos_sim-Recall@100  ...  dot_score-Accuracy@3  \\\n0               0.010086            0.962992  ...              0.704166   \n\n   dot_score-Accuracy@5  dot_score-Accuracy@10  dot_score-Precision@10  \\\n0              0.771749               0.848043                0.087512   \n\n   dot_score-Recall@10  dot_score-Precision@100  dot_score-Recall@100  \\\n0             0.840893                 0.010086              0.962992   \n\n   dot_score-MRR@10  dot_score-NDCG@10  dot_score-MAP@100  \n0           0.61888           0.670192           0.619506  \n\n[1 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>steps</th>\n      <th>cos_sim-Accuracy@1</th>\n      <th>cos_sim-Accuracy@3</th>\n      <th>cos_sim-Accuracy@5</th>\n      <th>cos_sim-Accuracy@10</th>\n      <th>cos_sim-Precision@10</th>\n      <th>cos_sim-Recall@10</th>\n      <th>cos_sim-Precision@100</th>\n      <th>cos_sim-Recall@100</th>\n      <th>...</th>\n      <th>dot_score-Accuracy@3</th>\n      <th>dot_score-Accuracy@5</th>\n      <th>dot_score-Accuracy@10</th>\n      <th>dot_score-Precision@10</th>\n      <th>dot_score-Recall@10</th>\n      <th>dot_score-Precision@100</th>\n      <th>dot_score-Recall@100</th>\n      <th>dot_score-MRR@10</th>\n      <th>dot_score-NDCG@10</th>\n      <th>dot_score-MAP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0.50446</td>\n      <td>0.704166</td>\n      <td>0.771749</td>\n      <td>0.848043</td>\n      <td>0.087512</td>\n      <td>0.840893</td>\n      <td>0.010086</td>\n      <td>0.962992</td>\n      <td>...</td>\n      <td>0.704166</td>\n      <td>0.771749</td>\n      <td>0.848043</td>\n      <td>0.087512</td>\n      <td>0.840893</td>\n      <td>0.010086</td>\n      <td>0.962992</td>\n      <td>0.61888</td>\n      <td>0.670192</td>\n      <td>0.619506</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"all_scores = pickle.load(open('/kaggle/working/dot_scorequeries_result_list.pkl','rb'))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:30:31.398002Z","iopub.execute_input":"2023-12-14T13:30:31.398732Z","iopub.status.idle":"2023-12-14T13:30:32.415592Z","shell.execute_reply.started":"2023-12-14T13:30:31.398690Z","shell.execute_reply":"2023-12-14T13:30:32.414775Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"all_scores.keys()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:33:51.516103Z","iopub.execute_input":"2023-12-14T13:33:51.516489Z","iopub.status.idle":"2023-12-14T13:33:51.522550Z","shell.execute_reply.started":"2023-12-14T13:33:51.516459Z","shell.execute_reply":"2023-12-14T13:33:51.521613Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"dict_keys(['cos_sim', 'dot_score'])"},"metadata":{}}]},{"cell_type":"code","source":"all_scores['cos_sim'][0][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T13:34:23.386493Z","iopub.execute_input":"2023-12-14T13:34:23.387398Z","iopub.status.idle":"2023-12-14T13:34:23.393773Z","shell.execute_reply.started":"2023-12-14T13:34:23.387364Z","shell.execute_reply":"2023-12-14T13:34:23.392676Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'corpus_id': 1202261, 'score': 0.5694323182106018}"},"metadata":{}}]}]}